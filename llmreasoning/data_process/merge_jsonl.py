# merge_jsonl_glob.py
import argparse
import glob
import json
import os

keys = ['question', 'answer', 'gen', 'accuracy']


def is_valid_field_content(field_name, content):
    """
    éªŒè¯å­—æ®µå†…å®¹æ˜¯å¦æœ‰æ•ˆ

    :param field_name: å­—æ®µå
    :param content: å­—æ®µå†…å®¹
    :return: (is_valid, error_message)
    """
    # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
    if content is None or (isinstance(content, str) and content.strip() == ''):
        return False, 'å†…å®¹ä¸ºç©º'

    # å¯¹äºç‰¹å®šå­—æ®µçš„éªŒè¯
    if field_name == 'accuracy':
        # accuracy åº”è¯¥æ˜¯å¸ƒå°”å€¼æˆ–å¯ä»¥è½¬æ¢ä¸ºå¸ƒå°”å€¼çš„å€¼
        if not isinstance(content, bool):
            if isinstance(content, (int, float)):
                if content not in [0, 1]:
                    return False, 'æ•°å€¼å‹accuracyå¿…é¡»æ˜¯0æˆ–1'
            elif isinstance(content, str):
                if content.lower() not in ['true', 'false', '0', '1']:
                    return False, "å­—ç¬¦ä¸²å‹accuracyå¿…é¡»æ˜¯'true', 'false', '0', '1'ä¹‹ä¸€"
            else:
                return False, "accuracyå¿…é¡»æ˜¯å¸ƒå°”å€¼ã€æ•°å€¼(0/1)æˆ–å­—ç¬¦ä¸²('true'/'false'/'0'/'1')"

    # question å’Œ answer å­—æ®µåº”è¯¥æ˜¯éç©ºå­—ç¬¦ä¸²
    if field_name in ['question', 'answer']:
        if not isinstance(content, str):
            return False, f'{field_name}å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹'
        if content.strip() == '':
            return False, f'{field_name}å†…å®¹ä¸èƒ½ä¸ºç©º'

    # gen å­—æ®µåº”è¯¥æ˜¯ä¸€ä¸ªåˆ—è¡¨
    if field_name == 'gen':
        if not isinstance(content, list):
            return False, 'genå¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹'
        if len(content) == 0:
            return False, 'genåˆ—è¡¨ä¸èƒ½ä¸ºç©º'

    return True, ''


def merge_jsonl_files(patterns, output_file, recursive=False):
    """
    æ ¹æ®é€šé…ç¬¦æ¨¡å¼åŒ¹é…å¹¶åˆå¹¶å¤šä¸ª JSONL æ–‡ä»¶ã€‚

    :param patterns: æ–‡ä»¶è·¯å¾„æ¨¡å¼åˆ—è¡¨ï¼Œå¦‚ ['data/*.jsonl', 'logs/**/*.jsonl']
    :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    :param recursive: æ˜¯å¦æ”¯æŒé€’å½’åŒ¹é…ï¼ˆå³ **ï¼‰
    """
    matched_files = []
    seen_files = set()

    print('ğŸ” æ­£åœ¨æœç´¢åŒ¹é…çš„æ–‡ä»¶...')
    for pattern in patterns:
        # ä½¿ç”¨ glob æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
        files = glob.glob(pattern, recursive=True)
        for file_path in files:
            if os.path.isfile(file_path) and file_path not in seen_files:
                matched_files.append(file_path)
                seen_files.add(file_path)

    if not matched_files:
        print('âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ã€‚')
        return

    # æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿åˆå¹¶é¡ºåºä¸€è‡´
    matched_files.sort()

    print(f'âœ… æ‰¾åˆ° {len(matched_files)} ä¸ªåŒ¹é…çš„æ–‡ä»¶ï¼š')
    for f in matched_files:
        print(f'   - {f}')

    # å¼€å§‹åˆå¹¶
    merged_count = 0
    skipped_count = 0
    with open(output_file, 'w', encoding='utf-8') as outfile:
        for file_path in matched_files:
            print(f'ğŸ“Œ æ­£åœ¨å¤„ç†: {file_path}')
            with open(file_path, 'r', encoding='utf-8') as infile:
                for line_num, line in enumerate(infile, 1):
                    line = line.strip()
                    if not line:
                        continue  # è·³è¿‡ç©ºè¡Œ
                    try:
                        data = json.loads(line)  # è§£æ JSON æ ¼å¼

                        # éªŒè¯å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
                        missing_keys = [key for key in keys if key not in data]
                        if missing_keys:
                            print(
                                f'âŒ æ–‡ä»¶ {file_path} ç¬¬ {line_num} è¡Œç¼ºå°‘å­—æ®µ: {missing_keys}'
                            )
                            skipped_count += 1
                            continue

                        # éªŒè¯å­—æ®µå†…å®¹æ˜¯å¦æ­£ç¡®
                        invalid_fields = []
                        for key in keys:
                            is_valid, error_msg = is_valid_field_content(
                                key, data[key])
                            if not is_valid:
                                invalid_fields.append(f'{key}({error_msg})')

                        if invalid_fields:
                            print(
                                f'âŒ æ–‡ä»¶ {file_path} ç¬¬ {line_num} è¡Œå­—æ®µå†…å®¹æ— æ•ˆ: {invalid_fields}'
                            )
                            skipped_count += 1
                            continue

                        outfile.write(line + '\n')
                        merged_count += 1
                    except json.JSONDecodeError as e:
                        print(
                            f'âŒ æ–‡ä»¶ {file_path} ç¬¬ {line_num} è¡Œ JSON è§£æé”™è¯¯: {e}')
                        skipped_count += 1

    print(f'\nâœ… åˆå¹¶å®Œæˆï¼å…±å†™å…¥ {merged_count} æ¡è®°å½•ï¼Œè·³è¿‡ {skipped_count} æ¡è®°å½•ã€‚')
    print(f'ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}')


def main():
    parser = argparse.ArgumentParser(
        description='åˆå¹¶æ¨¡ç³ŠåŒ¹é…è·¯å¾„ä¸‹çš„æ‰€æœ‰ JSONL æ–‡ä»¶ï¼ˆæ”¯æŒé€šé…ç¬¦ * å’Œ **ï¼‰')
    parser.add_argument('--patterns',
                        nargs='+',
                        help='æ–‡ä»¶è·¯å¾„åŒ¹é…æ¨¡å¼ï¼Œå¦‚: data/*.jsonl æˆ– logs/**/*.jsonl')
    parser.add_argument('--output',
                        default='merged_output.jsonl',
                        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: merged_output.jsonlï¼‰')

    args = parser.parse_args()
    merge_jsonl_files(args.patterns, args.output)


if __name__ == '__main__':
    main()
